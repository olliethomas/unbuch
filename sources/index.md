--- 
title: Fair Representations of Data
subtitle: 
author: Oliver Thomas
toc: false
...

begin+EmphBox

This is a work-in-progress document.
The writings, at times, may be entirely nonsense.

end+EmphBox

# Abstract
Consistent decision making as an idividual is hard. 
Once distributed to many people, making consistent decisions across an organisation is even harder.
Because of this, there is an appeal to automated, consistent decision making systems.
The promise is that these systems are reliable, transparent, and just.
However, in practice, this is not always the case, often to the detriment of society's least powerful.
The common retort is that machines aren't biased, but the data they learn from can be.
In this thesis I investigate this claim. 
I show that positive improvements can be made by changing the data, mapping from the original data to a "fair" representation.
I then demonstrate that we can query these changes to ask what needs to be changed about the data for it to stop being _not_ "fair".
Then, I draw a parallel between this work and the work of causality to demonstrate that we can identiy "at-risk" individuals.

# Table of contents

1. [Introduction](introduction.html) ([pdf](pdf/introduction.pdf))
2. [Chapter 1](fair_representations.html) ([pdf](pdf/fair_representations.pdf))
3. [Chapter 2](data_domain_representations.html) ([pdf](pdf/data_domain_represenations.pdf))
4. [Chapter 3](identifying_those_at_risk.html) ([pdf](pdf/identifying_those_at_risk.pdf))
5. [Appendix](appendix.html) ([pdf](pdf/appendix.pdf))

All chapters ([pdf](pdf/book.pdf))

# Citation 

To reference this thesis, please use this BibTex entry:

```bibtex
@phdthesis{FairReprTho21,
    author = {Thomas, Oliver},
    title  = {Fair Representations of Data},
    school = {University of Sussex},
    year   = {2021},
}
```
